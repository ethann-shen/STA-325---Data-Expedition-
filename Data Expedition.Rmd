---
title: "STA 325 - Data Expedition"
author: "Ethan Shen, Austin Jia, Malavi Ravindran, Steven Herrera"
date: "10/26/2019"
output: rmdformats::readthedown
---

```{r, echo = FALSE, include = FALSE}
# Installing packages
pkgTest <- function(x) {
  if (!require(x,character.only = TRUE)) {
    install.packages(x,dep=TRUE)
  }
}
pkgs <- c("ggplot2", "cowplot", "LaplacesDemon", "gam", "splines", "mgcv", "polywog", "DAAG", "gbm", "adabag")
for (pkg in pkgs) {
  pkgTest(pkg)
}
```

```{r, include = FALSE, echo = FALSE}
library(ggplot2)
library(cowplot)
library(LaplacesDemon)
library(gam)
library(splines)
library(mgcv)
library(polywog)
library(DAAG)
library(gbm)
library(adabag)
```

```{r}
train <- read.csv("data-train.csv")
test <- read.csv("data-test.csv")
```

# Exploratory Data Analysis

```{r}
train$Fr <- invlogit(train$Fr)

p1 <- qplot(train$St, bins = 20, 
            main = "Distribution of St", 
            xlab = "St", 
            ylab = "Frequency")
p2 <- qplot(train$Re, bins = 20,
            main = "Distribution of Re", 
            xlab = "Re", 
            ylab = "Frequency")
p3 <- qplot(train$Fr, bins = 20,
            main = "Distribution of Fr", 
            xlab = "Fr", 
            ylab = "Frequency")
cowplot::plot_grid(p1,p2,p3)
```

```{r warning = FALSE, message = FALSE}
m1 <- qplot(R_moment_1, data = train,
            main = "Distribution of Moment 1", 
            xlab = "Moment 1", 
            ylab = "Frequency")

mlog1 <- qplot(log(R_moment_1), data = train,
               main = "Distribution of log(Moment 1)", 
               xlab = "log(Moment 1)", 
               ylab = "Frequency")
m2 <- qplot(R_moment_2, data = train,
            main = "Distribution of Moment 2", 
            xlab = "Moment 2", 
            ylab = "Frequency")

mlog2 <- qplot(log(R_moment_2), data = train,
               main = "Distribution of log(Moment 2)", 
               xlab = "log(Moment 2)", 
               ylab = "Frequency")
m3 <- qplot(R_moment_3, data = train,
            main = "Distribution of Moment 3", 
            xlab = "Moment 3", 
            ylab = "Frequency")

mlog3 <- qplot(log(R_moment_3), data = train,
               main = "Distribution of log(Moment 3)", 
               xlab = "log(Moment 3)", 
               ylab = "Frequency")
m4 <- qplot(R_moment_4, data = train,
            main = "Distribution of Moment 4", 
            xlab = "Moment 4", 
            ylab = "Frequency")

mlog4 <- qplot(log(R_moment_4), data = train,
               main = "Distribution of log(Moment 4)", 
               xlab = "log(Moment 4)", 
               ylab = "Frequency")

cowplot::plot_grid(m1,m2,m3,m4)
cowplot::plot_grid(mlog1, mlog2, mlog3, mlog4)
```


```{r warning = FALSE, message = FALSE}
i1 <- ggplot(data=train, aes(x=Re,y=log(R_moment_1), color=as.factor(round(Fr, 3)))) + 
  geom_smooth() + 
  labs(y = "log(Moment 1)",
       color = "Fr")
i2 <- ggplot(data=train, aes(x=Re,y=log(R_moment_2), color=as.factor(round(Fr, 3)))) + 
  geom_smooth() + 
  labs(y = "log(Moment 2)",
       color = "Fr")
i3 <- ggplot(data=train, aes(x=Re,y=log(R_moment_3), color=as.factor(round(Fr, 3)))) + 
  geom_smooth() + 
  labs(y = "log(Moment 3)",
       color = "Fr")
i4 <- ggplot(data=train, aes(x=Re,y=log(R_moment_4), color=as.factor(round(Fr, 3)))) + 
  geom_smooth() + 
  labs(y = "log(Moment 4)",
       color = "Fr")

title_i <- ggdraw() + 
  draw_label("Interaction between Re and Fr") +
  theme(plot.margin = margin(0, 0, 0, 7))

plot_i <- plot_grid(
  i1 + theme(legend.position = "none"),
  i2 + theme(legend.position = "none"),
  i3 + theme(legend.position = "none"),
  i4 + theme(legend.position = "none"),
  nrow = 2
)

legend <- get_legend(i1)

with_title <- plot_grid(title_i, plot_i, ncol =1, rel_heights = c(0.1,1))

plot_grid(with_title, legend, rel_widths = c(3, 0.4))
```


# Moment 1 - Steven

### General Framework

### Linear Model (log transformations)


#### Using Ridge and LASSO regression 

### Polynomial 

### GAMs

### Splines

### Random Forest

### MSE Scores LATEX Table

### Flexibility vs. MSE Table

### Final Insights



# Moment 2 - Malavi

We will work with the logged value of the second moment as our response variable.

```{r}
library(tidyverse)
#dataset I will be working with

train <- train %>%
  mutate(log_second_moment = log(R_moment_2))
```

```{r}
trainSecondMomentFct <- train %>%
  mutate(Fr = factor(Fr))
```

First, we will see if there are important interactions within the data. 

```{r warning = FALSE, message = FALSE}
p <- ggplot(data=trainSecondMomentFct, aes(x=Re,y=log_second_moment, color=Fr)) + geom_smooth()
p
```


Next we will try fitting a simple linear regression model, taking into account this interaction effect. 

```{r}
lm.fit.2 <- lm(log_second_moment ~ St + Re + Fr + Re*Fr, data=train)
summary(lm.fit.2)
```


```{r}
cv.lm(train, form.lm = formula(log_second_moment ~ St + Re + Fr + Re*Fr), m = 5)
```

Next, we will try fititng a couple of different GAM models.

```{r}
gam.fit.2a <- gam(log_second_moment~ s(St) + Re + Fr, data=train)
summary(gam.fit.2a)
```


```{r}
gam.fit.2b <- gam(log_second_moment~ s(St) + Re + Fr + Re:Fr, data=train)
summary(gam.fit.2b)
```


```{r}
anova(gam.fit.2a, gam.fit.2b, test = "F")
```

Thus, we will consider a GAM model with interactions. Now we wil test this against a natural spline. 


```{r}
gam.fit.2c <- gam(log_second_moment~ ns(St) + Re + Fr + Re:Fr, data=train)
summary(gam.fit.2c)
```




```{r}
anova(gam.fit.2c, gam.fit.2b, test = "F")
```

We will work with the regular, rather than natural spline for St. 
Finding the cv error of this model: 

```{r}
library(gamclass)
gamclass::CVgam(log_second_moment ~ s(St) + Re + Fr + Re:Fr, data = train, nfold = 5, method = "GCV.Cp")
```

We will also try fitting splines.

```{r}
spline.fit.2a <- lm(log_second_moment ~ ns(log(St) + Re) + ns(Fr), data = train) 
spline.fit.2b <- lm(log_second_moment ~ ns(St + Re) + bs(Fr), data = train) 
```

```{r}
summary(spline.fit.2a)
AIC(spline.fit.2a)
```

```{r}
summary(spline.fit.2b)
AIC(spline.fit.2b)
```

```{r}
anova(spline.fit.2a, spline.fit.2b, test = "F")
```

Looks like the linear model performs slightly better than the GAM. We will use this as our final model to predict the second moment. 

```{r}
lm.fit.2 <- lm(log(R_moment_2) ~ St + Re + Fr + Re*Fr, data=train)

```


```{r}
lm.predictions.2.log <- predict(lm.fit.2, data = test)
```

```{r}
lm.predictions.2 <- exp(lm.predictions.2.log)
lm.predictions.2
```

# Moment 3 - Austin

### General Framework

### Linear Model (log transformations)

```{r}
lm.fit.3 <- lm(R_moment_3 ~ St + Re + Fr, data = train) 
summary(lm.fit.3)
predict(lm.fit.3, list(St = test$St, Re = test$Re, Fr = test$Fr))
plot(lm.fit.3)


cv.lm(train, form.lm = formula(log(R_moment_3) ~ St + Re + Fr), m = 10)
```

### Polynomial 

```{r}
cv1 <- cv.polywog(R_moment_3 ~ St + Re + Fr,
                  data = train,
                  degrees.cv = 1:4,
                  nfolds = 5,
                  thresh = 1e-4)
print(cv1)

## Extract best model and bootstrap
fit1 <- cv1$polywog.fit
fit1 <- bootPolywog(fit1, nboot = 5)
summary(fit1)
```


### GAMs

```{r}
qplot(R_moment_3, data = train,
      main = "Distribution of Moment 3", 
      xlab = "Moment 3", 
      ylab = "Frequency")

qplot(log(R_moment_3), data = train,
      main = "Distribution of log(Moment 3)", 
      xlab = "log(Moment 3)", 
      ylab = "Frequency")

```

```{r, include=FALSE}
cross_validate <- function(model_type, formula, data, k, log_response) {
  #Randomly shuffle the data
  shuffled_data<-data[sample(nrow(data)),]
  #Create 10 equally size folds
  folds <- cut(seq(1,nrow(shuffled_data)),breaks=k,labels=FALSE)
  #Perform 10 fold cross validation
  avg_mse <- 0
  for(i in 1:k){
    #Segement your data by fold using the which() function 
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- shuffled_data[testIndexes, ]
    trainData <- shuffled_data[-testIndexes, ]
    
    model <- model_type(as.formula(formula), data=trainData)
    # validate model
    if (log_response) {
      test_mse <-  mean((exp(predict(model, testData)) - testData$BWTG_C)^2)
    }
    else {
      test_mse <- mean((predict(model, testData) - testData$BWTG_C)^2)
    }
    avg_mse <- avg_mse + test_mse
  }
  print('Average test MSE')
  print(avg_mse / k)
  return (avg_mse / k)
}
```

```{r}
gam.1.3 <- gam(log(R_moment_3) ~ s(St) + Re + Fr, data = train)
summary(gam.1.3)
gam.2.3 <- gam(log(R_moment_3) ~ s(log(St)) + Re + Fr, data = train)
summary(gam.2.3) 
```

Logging `St` definitely helps

```{r}
#GOOD MODEL 
gam.3.3 <- gam(log(R_moment_3) ~ s(log(St)) + Re + Fr + Re * Fr, data = train)
summary(gam.3.3)
anova(gam.2.3, gam.3.3, test = "F")
plot(gam.3.3, pages=1, residuals=TRUE, all.terms=TRUE, shade=TRUE, shade.col=2)
```


### Splines

```{r}
spline.1.3 <- lm(R_moment_3 ~ ns(St, df = 2) + ns(Re, df = 4) + ns(Fr, df=2), data = train) #.3942
spline.2.3 <- lm(R_moment_3 ~ ns(log(St), df = 4) + Re + ns(Fr, df=2), data = train) #.3366
spline.3.3 <- lm(log(R_moment_3) ~ ns(log(St) + Re, df = 4) + ns(Fr, df=2), data = train) #.4697, AIC 4410.8
spline.4.3 <- lm(log(R_moment_3) ~ ns(St + Re) + bs(Fr), data = train) #.4607

summary(spline.1.3)
summary(spline.2.3)
summary(spline.3.3)
summary(spline.4.3)

summary(spline.3.3)
AIC(spline.3.3)
summary(spline.4.3)
AIC(spline.4.3)
anova(spline.3.3, spline.4.3, test = "F")
```

###Boosting

```{r}
# set.seed(1)
# blehbleh <- gbm(R_moment_3 ~ St + Fr + Re, data = train, 
#                 distribution = "gaussian", n.trees = 5000)
# 
# summary(blehbleh)
# 
# boosting.cv(formula, data, v = 10, boos = TRUE, mfinal = 100, 
#             coeflearn = "Breiman", control, par=FALSE)
```


### Random Forest

### MSE Scores LATEX Table

### Flexibility vs. MSE Table

### Final Insights




# Moment 4 - Ethan 


First, we will see if there are important interactions within the data. 

```{r warning = FALSE, message = FALSE}
ggplot(data=train, aes(x=Re,y=log(R_moment_4), color=as.factor(Fr))) + geom_smooth()

```
### Linear Model (log transformations)

```{r}
lm.fit.4 <- lm(log(R_moment_4) ~ St + Re + Fr + Re*Fr, data = train) 
summary(lm.fit.4)
cv.lm(train, form.lm = formula(log(R_moment_4) ~ St + Re + Fr + Re*Fr), m = 5)
```

### GAMs

```{r}
gam.4a <- gam(log(R_moment_4) ~ s(St) + bs(Re) + bs(Fr), data = train)
summary(gam.4a)
gam.4b <- gam(log(R_moment_4) ~ s(St) + bs(Re) + bs(Fr)+ bs(Re * Fr), data = train)
summary(gam.4b) 
anova(gam.4a, gam.4b, test = "F")
```

Adding the interaction helps. 

Testing is natural spline is btter than smoothing spline. 

```{r}
#GOOD MODEL 
gam.4c <- gam(log(R_moment_4) ~ ns(St) + bs(Re) + bs(Fr) + bs(Re * Fr), data = train)
summary(gam.4c)
anova(gam.4b, gam.4c, test = "F")


plot(gam.4c, pages=1, residuals=TRUE, all.terms=TRUE, shade=TRUE, shade.col=2)
```
Natural spline is better. 

```{r}
#gam.check(gam.4c)
```

```{r}
CVgam(log(R_moment_4) ~ ns(St) + bs(Re) + bs(Fr) + bs(Re * Fr), data = train, nfold = 5, method = "GCV.Cp")
```

### Splines

```{r}
spline.4a <- lm(log(R_moment_4) ~ bs(St) + ns(Re) + ns(Fr), data = train) #.4697, AIC 4410.8
spline.4b <- lm(log(R_moment_4) ~ bs(St) + ns(Re) + ns(Fr) + ns(Re*Fr), data = train) #.4607

#BEST CV w intrpretable model lmfao
gamclass::CVgam(log(R_moment_4) ~ bs(St) + ns(Re) + ns(Fr) + ns(Re*Fr), data = train, nfold = 5, method = "GCV.Cp")


summary(spline.4a)
AIC(spline.4a)
summary(spline.4b)
AIC(spline.4b)
anova(spline.4a, spline.4b, test = "F")
```

```{r}
data.frame(exp(predict(gam.4c, data = test)))
```


